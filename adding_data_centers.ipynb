{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Install packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# work with data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import h5pyd\n",
        "import yaml\n",
        "\n",
        "# work with geospatial\n",
        "import geopandas as gpd\n",
        "from scipy.interpolate import griddata\n",
        "from pyproj import Proj, Transformer\n",
        "from scipy.spatial import cKDTree\n",
        "\n",
        "# optimization\n",
        "import gurobipy as gp\n",
        "from gurobipy import GRB\n",
        "\n",
        "# visualization\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "\n",
        "\n",
        "# work with time\n",
        "import pytz\n",
        "import dateutil\n",
        "from datetime import datetime, timezone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get geometries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n"
          ]
        }
      ],
      "source": [
        "# Arizona shapefile\n",
        "\n",
        "us_states = gpd.read_file('data/data_siting/cb_2018_us_state_500k/cb_2018_us_state_500k.shp')\n",
        "arizona = us_states[us_states['NAME'] == 'Arizona']\n",
        "arizona.to_crs(\"EPSG:5070\", inplace=True) # we use EPSG 5070 to get more accurate area measurements. https://epsg.io/5070-1252\n",
        "\n",
        "# water basins shapefile\n",
        "\n",
        "huc_subbasins = gpd.read_file('data/data_siting/HUC8_CONUS/HUC8_US.shp') # read in subbasins\n",
        "huc_subbasins['has_arizona'] = huc_subbasins['STATES'].map(lambda x: 'AZ' in x)\n",
        "huc_subbasins_az = huc_subbasins[huc_subbasins['has_arizona']]\n",
        "huc_subbasins_az.to_crs(\"EPSG:5070\", inplace=True)\n",
        "\n",
        "huc_subbasins_az['HUC6'] = huc_subbasins_az['HUC8'].map(lambda x: x[:6])\n",
        "\n",
        "# also, in case we want centroid:\n",
        "huc_subbasins_az['centroid'] = huc_subbasins_az.to_crs(\"+proj=cea\").centroid.to_crs(huc_subbasins_az.crs)\n",
        "\n",
        "# transform centroid to lat and lon\n",
        "transformer = Transformer.from_crs(5070, 4326)\n",
        "\n",
        "huc_subbasins_az['centroid_lat_lon'] = huc_subbasins_az['centroid'].map(lambda pt: transformer.transform(pt.x, pt.y))\n",
        "\n",
        "\n",
        "# read in US counties\n",
        "us_counties = gpd.read_file('data/data_siting/cb_2018_us_county_500k/cb_2018_us_county_500k.shp') # read in counties\n",
        "arizona_counties = us_counties[us_counties['STATEFP'] == '04'] # filter to arizona\n",
        "arizona_counties.to_crs(\"EPSG:5070\", inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Solar and Wind Data Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def shift_from_utc(data, offset_hours, time_gap):\n",
        "    \"\"\"\n",
        "    Shift hourly values from UTC to a timezone that is `offset_hours`\n",
        "    behind UTC.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        data: np.ndarray\n",
        "            Array of data\n",
        "        offset_hours: int\n",
        "            Number of hours to offset\n",
        "        time_gap: float\n",
        "            Time gap between subsequent data points\n",
        "    \"\"\"\n",
        "\n",
        "    # roll left by offset_hours:\n",
        "    hour_multiplier = 1/time_gap\n",
        "    shift_idx = int(offset_hours * hour_multiplier)\n",
        "\n",
        "    return np.concatenate([data[shift_idx:], data[:shift_idx]], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "# access NSRDB stuff: https://github.com/NREL/hsds-examples/tree/master\n",
        "\n",
        "# takes around a minute to run \n",
        "\n",
        "solar = h5pyd.File(\"/nrel/nsrdb/v3/nsrdb_2013.h5\")\n",
        "meta = pd.DataFrame(solar['meta'][...])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "# find the nearest timeseries\n",
        "\n",
        "dset_coords = solar['coordinates'][...]\n",
        "tree = cKDTree(dset_coords)\n",
        "\n",
        "def nearest_site_solar(tree, lat_coord, lon_coord):\n",
        "    \"\"\" \n",
        "    Find the nearest site in the solar dataset.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        tree: scipy.spatial.cKDTree\n",
        "            Lookup tree for nearest neighbor\n",
        "        lat_coord: float\n",
        "            Latitude\n",
        "        lon_coord: float\n",
        "            Longitude\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        Index of closest point in the solar dataset\n",
        "    \"\"\"\n",
        "\n",
        "    lat_lon = np.array([lat_coord, lon_coord])\n",
        "    _, pos = tree.query(lat_lon)\n",
        "    return pos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "# collect GHI at every point\n",
        "\n",
        "ghi_data = solar['ghi']\n",
        "\n",
        "ghi_subbasins = np.zeros((ghi_data.shape[0], huc_subbasins_az.shape[0])) # rows: timestamps, # columns: locations\n",
        "\n",
        "# for each arizona subbasin centroid, get the solar data of the closest point\n",
        "for idx, centroid_lat_lon in enumerate(huc_subbasins_az['centroid_lat_lon']):\n",
        "    centroid_idx = nearest_site_solar(tree, centroid_lat_lon[0], centroid_lat_lon[1])\n",
        "    ghi_tseries = ghi_data[:, centroid_idx] / ghi_data.attrs['psm_scale_factor'] # units: W/m^2. https://nsrdb.nrel.gov/data-sets/us-data\n",
        "\n",
        "    ghi_subbasins[:, idx] = ghi_tseries\n",
        "\n",
        "ghi_subbasins = shift_from_utc(ghi_subbasins, 7, 0.5) # shift to Arizona time. 7 hours delay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "# timestamp\n",
        "\n",
        "# convert timestamps from UTC to Arizona time: https://www.geeksforgeeks.org/how-to-convert-date-and-time-with-different-timezones-in-python/\n",
        "AZ_time = pytz.timezone('America/Phoenix')\n",
        "\n",
        "time_index = pd.to_datetime(solar['time_index'][...].astype(str))\n",
        "\n",
        "time_index = time_index.tz_localize(pytz.utc)\n",
        "time_index = time_index.map(lambda x: x.astimezone(AZ_time)) # change from UTC to Arizona time\n",
        "time_index = shift_from_utc(time_index, 7, 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_GHI = np.max(ghi_subbasins) # obtain max irradiance\n",
        "\n",
        "# and then aggregate the GHI values into days\n",
        "ghi_subbasins = ghi_subbasins.reshape((ghi_data.shape[0]//48, 48, huc_subbasins_az.shape[0])) # note grouping by 48, because we are in half hour intervals\n",
        "\n",
        "ghi_subbasins = ghi_subbasins.sum(axis=1)*0.5 # W/(m^2 * day). Don't forget time step is a half hour"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save solar data\n",
        "ghi_subbasins_df = pd.DataFrame(ghi_subbasins)\n",
        "ghi_subbasins_df.to_csv(\"data/data_siting/GHI_subbasin_AZ.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "# now think about generation per watt of capacity, per day\n",
        "ghi_subbasins_df = pd.read_csv(\"data/data_siting/GHI_subbasin_AZ.csv\", index_col=0)\n",
        "# ghi_subbasins_df_per_watt = ghi_subbasins_df/max_GHI\n",
        "ghi_subbasins_df_per_watt = ghi_subbasins_df/1000\n",
        "ghi_subbasins_df_per_watt.to_csv(\"data/data_siting/GHI_subbasin_AZ_per_watt.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# solar capacity computation: oof I will do this later. just assume 21% efficiency for now. https://css.umich.edu/publications/factsheets/energy/solar-pv-energy-factsheet#:~:text=Solar%20Resources%20and%20Potential&text=PV%20conversion%20efficiency%20is%20the,that%20is%20converted%20to%20electricity.&text=Though%20the%20average%20efficiency%20of,with%20efficiencies%20near%2040%259.\n",
        "\n",
        "# solar panel price: $2.06/W, https://www.energysage.com/local-data/solar-panel-cost/az/\n",
        "# and roughly solar panels are 200 W/m^2. https://www.sunstyle.com/portfolio/square-meter-solar-family-need/#:~:text=The%20efficiency%20of%20solar%20panels,value%20of%20175%20Wp%2Fm%C2%B2.\n",
        "# which means, 200W of solar panel gets you just the irradiation times 21%.\n",
        "# so, 1W of solar panel gets you the irradiation times 21%/200, which is around 0.1%.\n",
        "# so basically just divide the irradiance by 1000. https://www.greenlancer.com/post/solar-panel-wattage-output-explained#:~:text=A%20solar%20panel%20rating%20measures,sunlight%20at%201000W%2Fsquare%20meters.\n",
        "# so, say solar panels are $412/m^2. And then we multiply the production by 21%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wind = h5pyd.File(\"/nrel/wtk-us.h5\")\n",
        "\n",
        "# rated power\n",
        "# lets try this wind turbine model GE1.5, just out of commonality. https://en.wind-turbine-models.com/turbines/565-ge-vernova-ge-1.5s\n",
        "# lets say 77m height\n",
        "# and 80m diameter --> regime is around 42m to 112m\n",
        "# so let's take windspeed at 77m\n",
        "\n",
        "# convert using the power curve\n",
        "# https://nrel.github.io/turbine-models/DOE_GE_1.5MW_77.html\n",
        "GE_power_curve = pd.read_csv('data/data_siting/DOE_GE_1.5MW_77.csv')\n",
        "GE_power_curve['Power [kW]'] = GE_power_curve['Power [kW]'].map(lambda x: np.clip(x, 0, np.inf)) # don't allow negative power production\n",
        "\n",
        "wind_speed = wind['windspeed_80m'] # start working with wind speed data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# note: the wind data is hourly\n",
        "wind_time = pd.DataFrame({'datetime': wind['datetime']})\n",
        "wind_time['datetime'] = wind_time['datetime'].apply(dateutil.parser.parse)\n",
        "wind_time['datetime'] = wind_time['datetime'].map(lambda x: x.replace(tzinfo=timezone.utc))\n",
        "\n",
        "# get 2013 data when querying for specific locations, right now data is too large\n",
        "# just select 2013 data\n",
        "wind_time['year'] = wind_time['datetime'].map(lambda x: x.year)\n",
        "wind_time = wind_time[wind_time['year'] == 2013]\n",
        "indices_2013 = wind_time.index\n",
        "\n",
        "AZ_time = pytz.timezone('America/Phoenix')\n",
        "wind_time['datetime'] = wind_time['datetime'].map(lambda x: x.astimezone(AZ_time)) # change from UTC to Arizona time\n",
        "\n",
        "# shift dataset to start at Arizona midnight\n",
        "wind_time = shift_from_utc(wind_time, 7, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def nearest_wind_site(data, lat_index, lon_index):\n",
        "    \"\"\" \n",
        "    Get nearest site with wind data to input location.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        data: h5pyd._hl.dataset.Dataset\n",
        "            Full dataset, for coordinates\n",
        "        lat_index: float\n",
        "            Latitude\n",
        "        lon_index: float\n",
        "            Longitude\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        Longitude and latitude index of closest point in the wind dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    data_coords = data['coordinates']\n",
        "\n",
        "    # find nearby point, convert to x/y indices\n",
        "    projstring = \"\"\"+proj=lcc +lat_1=30 +lat_2=60 \n",
        "                    +lat_0=38.47240422490422 +lon_0=-96.0 \n",
        "                    +x_0=0 +y_0=0 +ellps=sphere \n",
        "                    +units=m +no_defs \"\"\"\n",
        "    project_lcc = Proj(projstring)\n",
        "    origin_ll = reversed(data_coords[0][0]) # origin. But flip order to get lon, lat\n",
        "    origin = project_lcc(*origin_ll)\n",
        "\n",
        "    coords = (lon_index, lat_index) # note the order of lon, lat\n",
        "    coords = project_lcc(*coords)\n",
        "    delta = np.subtract(coords, origin)\n",
        "    ij = [int(round(x/2000)) for x in delta] # by rounding, we just get the nearest lattice point\n",
        "    return tuple(reversed(ij))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "# convert wind to energy\n",
        "\n",
        "with open(\"data/data_siting/DOE_GE_1.5MW_77.yaml\", 'r') as f:\n",
        "    turbine_specs = yaml.safe_load(f)\n",
        "    cut_in = turbine_specs['cut_in_wind_speed']\n",
        "    cut_out = turbine_specs['cut_out_wind_speed']\n",
        "    rated_wind = turbine_specs['rated_wind_speed']\n",
        "    rated_power = turbine_specs['rated_power']\n",
        "\n",
        "measured_winds = GE_power_curve['Wind Speed [m/s]'].values\n",
        "measured_wind_power = GE_power_curve['Power [kW]'].values\n",
        "\n",
        "def wind_speed_to_energy(tseries):\n",
        "    \"\"\" \n",
        "    Converts wind speed to energy.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        tseries: np.ndarray\n",
        "            Time series array of wind speed values (m/s)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        Time series array of wind energy multiplier values (W produced, per W of capacity).\n",
        "    \"\"\"\n",
        "\n",
        "    wind_measure_array = np.repeat(measured_winds.reshape(-1,1), tseries.shape[0], axis=1) # for each of the time series stamps, keep track of relation to measured wind speed\n",
        "\n",
        "    # find the index closest to the time series\n",
        "    wind_diffs = wind_measure_array - tseries\n",
        "    diff_min_pos = np.argmax(wind_diffs >= 0, axis=0)\n",
        "\n",
        "    # and then interpolate\n",
        "    # if diff_min_pos = 0, either the wind speed was too low (below lowest measurement), or the wind speed was too high (above highest measurement)\n",
        "    computed_power = np.where(diff_min_pos > 0, ((measured_winds[diff_min_pos] - tseries)/(measured_winds[diff_min_pos] - measured_winds[diff_min_pos-1])) * measured_wind_power[diff_min_pos-1] + ((tseries - measured_winds[diff_min_pos-1])/(measured_winds[diff_min_pos] - measured_winds[diff_min_pos - 1])) * measured_wind_power[diff_min_pos], 0)\n",
        "\n",
        "    # divide by rated power\n",
        "    computed_power /= rated_power\n",
        "\n",
        "    # however, special cases: below cut-in, between rated and cut-out wind speed, above cut-out wind speed\n",
        "    computed_power = np.where((tseries < cut_in) | (tseries > cut_out), 0, computed_power) # clip below cut-in power or above cut_out power\n",
        "    computed_power = np.where((tseries > rated_wind) & (tseries < cut_out), 1, computed_power) # max out power production between rated and cut-out wind speed\n",
        "    \n",
        "    return computed_power"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get wind speeds at closest location for each of the Arizona subbasins\n",
        "\n",
        "wind_speed_subbasins = np.zeros((wind_time.shape[0], huc_subbasins_az.shape[0]))\n",
        "\n",
        "# for each wind subbasin centroid, get wind data of closest point\n",
        "for idx, centroid_lat_lon in enumerate(huc_subbasins_az['centroid_lat_lon']):\n",
        "    centroid_idx = nearest_wind_site(wind, centroid_lat_lon[0], centroid_lat_lon[1])\n",
        "    wind_tseries = wind_speed[indices_2013, centroid_idx[0], centroid_idx[1]] # units: m/s.\n",
        "\n",
        "    wind_speed_subbasins[:, idx] = wind_tseries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# intermediate save checkpoint. So we don't have to wait again\n",
        "wind_speed_subbasins_df = pd.DataFrame(wind_speed_subbasins)\n",
        "wind_speed_subbasins_df.to_csv(\"data/data_siting/wind_speed_subbasin_AZ.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# read in csv\n",
        "wind_speed_subbasins_df = pd.read_csv(\"data/data_siting/wind_speed_subbasin_AZ.csv\", index_col=0)\n",
        "wind_speed_subbasins_np = wind_speed_subbasins_df.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "# convert wind speed data to wind power\n",
        "\n",
        "wind_power_subbasins = np.zeros(wind_speed_subbasins_np.shape)\n",
        "\n",
        "for idx in range(wind_speed_subbasins_np.shape[1]):\n",
        "    curr_tseries = wind_speed_subbasins_np[:, idx]\n",
        "    curr_power_tseries = wind_speed_to_energy(curr_tseries)\n",
        "    wind_power_subbasins[:, idx] = curr_power_tseries # this is in units of how much power you get per watt installed\n",
        "\n",
        "# don't forget to shift dataset to Arizona time\n",
        "wind_power_subbasins = shift_from_utc(wind_power_subbasins, 7, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save the data\n",
        "wind_power_subbasins_df = pd.DataFrame(wind_power_subbasins)\n",
        "wind_power_subbasins_df.to_csv(\"data/data_siting/wind_power_per_watt_hourly.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [],
      "source": [
        "# aggregate into days\n",
        "wind_power_subbasins_np = pd.read_csv(\"data/data_siting/wind_power_per_watt_hourly.csv\", index_col=0).values\n",
        "wind_power_subbasins_np = wind_power_subbasins_np.reshape((wind_power_subbasins_np.shape[0]//24, 24, wind_power_subbasins_np.shape[1]))\n",
        "wind_power_subbasins_np = np.sum(wind_power_subbasins_np, axis=1) # no need for multiplier. because data is hourly already.\n",
        "\n",
        "# save new data\n",
        "wind_power_subbasins_daily_df = pd.DataFrame(wind_power_subbasins_np)\n",
        "wind_power_subbasins_daily_df.to_csv(\"data/data_siting/wind_power_per_watt_daily.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# wind calculations:\n",
        "# price: let's say $1500/kW --> $1,500,000/MW. https://www.energy.gov/eere/wind/articles/land-based-wind-market-report-2022-edition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Gather data for HUC8 level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get lists of HUC8 subbasins that group into HUC6 basins\n",
        "huc6_huc8_dict = dict()\n",
        "\n",
        "for huc6 in huc_subbasins_az['HUC6'].unique():\n",
        "    huc_filter = huc_subbasins_az[huc_subbasins_az['HUC6'] == huc6]\n",
        "    huc6_huc8_dict[huc6] = huc_filter['HUC8'].to_list()\n",
        "\n",
        "# data values for HUC8 regions generated from the paper by Abu Bakar Siddik et al 2021: https://iopscience.iop.org/article/10.1088/1748-9326/abfba1?_sp=b48260d8-0a7b-4784-9d4b-0e1ac60ee727\n",
        "water_carbon = pd.read_excel(\"data/data_siting/DC_footprint/SI_XLS/Results.xlsx\", sheet_name=\"Table 3\", skiprows=1)\n",
        "\n",
        "water_carbon['HUC8_str'] = water_carbon['HUC8'].map(lambda x: ''.join(['0']*(8-len(str(x)))) + str(x))\n",
        "\n",
        "# filter to only HUC rows\n",
        "water_carbon['not_nan'] = ~water_carbon['WSF_1MW_DC'].isna()\n",
        "water_carbon = water_carbon[water_carbon['not_nan']]\n",
        "\n",
        "# now merge with the arizona HUC data\n",
        "huc_subbasins_az = huc_subbasins_az.merge(water_carbon, how=\"inner\", left_on=\"HUC8\", right_on=\"HUC8_str\")\n",
        "huc_subbasins_az = gpd.clip(huc_subbasins_az, arizona)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# estimations of existing data centers: https://www.datacentermap.com/\n",
        "# power of existing data centers? Unclear. https://baxtel.com/data-center/phoenix\n",
        "# well, in total there is around 602.8 MW in the Phoenix area. https://azbigmedia.com/real-estate/phoenix-ranks-4th-among-north-american-data-center-markets/\n",
        "# and, in the Phoenix area there are 124 data centers. https://www.datacentermap.com/usa/arizona/\n",
        "# so, let's say on average, each existing data center takes on 5 MW of load.\n",
        "\n",
        "# existing inventory HUC8\n",
        "# 15050301: 6\n",
        "# 15050302: 2\n",
        "# 15050303: 4 (from Eloy) \n",
        "# 15050100: 17 (from Mesa airport AZA) 13 (from Chandler airport CHD) 4 (from Gilbert)\n",
        "# 15060106: 2 (from Mesa) 25 (from Phoenix airport and Scottsdale) 2 (from upper Scottsdale)\n",
        "# 15070102: 6 (from Deer Valley) 40 (from Litchfield park airport)\n",
        "# 15070103: 1 (from Buckeye/Arlington)\n",
        "\n",
        "\n",
        "# totals (done by hand, because data lies behind paywalls):\n",
        "# 15050301: 6\n",
        "# 15050302: 2\n",
        "# 15050303: 4\n",
        "# 15050100: 34\n",
        "# 15060106: 29\n",
        "# 15070102: 46\n",
        "# 15070103: 1\n",
        "\n",
        "existing_data_centers = {\n",
        "    15050301: 6,\n",
        "    15050302: 2,\n",
        "    15050303: 4,\n",
        "    15050100: 34,\n",
        "    15060106: 29,\n",
        "    15070102: 46,\n",
        "    15070103: 1\n",
        "}\n",
        "\n",
        "huc_subbasins_az['existing_MW'] = huc_subbasins_az['HUC8_y'].map(lambda x: existing_data_centers.get(x, 0)*5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n"
          ]
        }
      ],
      "source": [
        "# electricity prices\n",
        "# https://www.energysage.com/local-data/electricity-cost/az/\n",
        "# cochise county: 16 cents/kwh\n",
        "# coconino county: 15 cents/kwh\n",
        "# gila county: 20 cents/kwh\n",
        "# la paz county: 15 cents/kwh\n",
        "# maricopa county: 15 cents/kwh\n",
        "# mohave county: 18 cents/kwh\n",
        "# navajo county: 15 cents/kwh\n",
        "# pima county: 18 cents/kwh\n",
        "# pinal county: 16 cents/kwh\n",
        "# yavapai county: 15 cents/kwh\n",
        "# yuma county: 15 cents/kwh\n",
        "\n",
        "# units: cents/kwh\n",
        "elec_price_dict = {'Cochise': 16, 'Coconino': 15, 'Gila': 20, 'La Paz': 15, 'Maricopa': 15, 'Mohave': 18, \n",
        "                   'Navajo': 15, 'Pima': 18, 'Pinal': 16, 'Yavapai': 15, 'Yuma': 15}\n",
        "\n",
        "# new units: dollars/mw = cents/kwh * (0.01 dollar/1 cent) * (1000 kwh/1 mw)\n",
        "elec_price_dict = {k: 10*v for k, v in elec_price_dict.items()}\n",
        "\n",
        "has_elec_price = set(elec_price_dict.keys())\n",
        "num_elec_price = len(has_elec_price)\n",
        "\n",
        "# find arizona counties with electricity price data\n",
        "arizona_counties['has_elec_price'] = arizona_counties['NAME'].map(lambda x: x in has_elec_price)\n",
        "arizona_counties_elec_price = arizona_counties[arizona_counties['has_elec_price']]\n",
        "arizona_counties_elec_price['elec_price'] = arizona_counties_elec_price['NAME'].map(lambda x: elec_price_dict[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO move to a Python utils file\n",
        "\n",
        "class resolve_regions:\n",
        "    \"\"\" \n",
        "    Converts one subdivision of space (e.g., county) into another subdivision of space (e.g., HUC8.)\n",
        "\n",
        "    Averages out value of interest according to amount of overlap with the first subdivision of space, or the \n",
        "    closest region. \n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, from_df, to_df, value_col, id_row):\n",
        "        \"\"\" \n",
        "        Init method for the class resolve_regions.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "            from_df: gpd.GeoDataFrame\n",
        "                Dataframe to convert from\n",
        "            to_df: gpd.GeoDataFrame\n",
        "                Dataframe to convert to\n",
        "            value_col: string\n",
        "                Name of column with values of interest\n",
        "            id_row: string\n",
        "                Name of column with unique identifiers, in to_df\n",
        "        \"\"\"\n",
        "\n",
        "        self.from_df = from_df\n",
        "        self.to_df = to_df\n",
        "        self.value_col = value_col\n",
        "        self.id_row = id_row\n",
        "\n",
        "# TODO: currently this only handles average. We can also functionalize it to handle other functions.\n",
        "    def weighted_computation(self, id):\n",
        "        \"\"\" \n",
        "        Perform the weighted average computation for the output row with identification id.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "            id: string\n",
        "                Unique ID for the output row\n",
        "        \"\"\"\n",
        "\n",
        "        to_geometry = self.to_df[self.to_df[self.id_row] == id]['geometry'].iloc[0] # extract geometry of to_df\n",
        "        from_to_intersect = self.from_df['geometry'].intersection(to_geometry) # obtain intersections\n",
        "\n",
        "        area_sum = np.sum(from_to_intersect.area)\n",
        "\n",
        "        if area_sum > 0: # some intersection\n",
        "            weighted_val = 0 # keep track of weighted sum for value of interest\n",
        "\n",
        "            for idx, area in from_to_intersect.area.items():\n",
        "                weighted_val += self.from_df.loc[idx, self.value_col]*area\n",
        "            \n",
        "            weighted_val /= area_sum\n",
        "        \n",
        "        else:\n",
        "            from_to_distance = self.from_df['geometry'].distance(to_geometry) # obtain distances\n",
        "            from_to_distance.sort_values(ascending=True, inplace=True)\n",
        "            lowest_idx = from_to_distance.index[0]\n",
        "\n",
        "            weighted_val = self.from_df.loc[lowest_idx, self.value_col]\n",
        "\n",
        "        return weighted_val\n",
        "\n",
        "    def convert_regions(self):\n",
        "        \"\"\" \n",
        "        Perform conversion between the subdivisions of space, and average the value of interest.\n",
        "        \"\"\"\n",
        "\n",
        "        converted_value_list = []\n",
        "\n",
        "        for id in self.to_df[self.id_row]: # iterate over geometries of to_df\n",
        "            converted_value_list.append(self.weighted_computation(id))\n",
        "\n",
        "        self.to_df[self.value_col] = converted_value_list # set the output values after conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# assign electricity price in HUC8 regions to closest county with price\n",
        "# consider: if desired, we can add some random noise\n",
        "\n",
        "# build up the elec_price ($/MW) column\n",
        "\n",
        "county_to_huc_elec_price = resolve_regions(arizona_counties_elec_price, huc_subbasins_az, 'elec_price', 'HUC8_y')\n",
        "county_to_huc_elec_price.convert_regions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# next, let's take a look at land prices. \n",
        "# we get TIF files from here: https://www.pnas.org/doi/10.1073/pnas.2012865117. Units: log(2017$/hectare)\n",
        "# first, let's convert into linear units.\n",
        "\n",
        "from osgeo import gdal\n",
        "\n",
        "import rasterio\n",
        "\n",
        "# perhaps we can use this for modifying the tif file: https://github.com/rasterio/rasterio/discussions/3006\n",
        "\n",
        "if False: # only need to do this once\n",
        "    # convert $/hectare to $/acre\n",
        "    acre_to_hectare = 2.47105\n",
        "\n",
        "    # original data is in ln(2017$/hectare). Transform to linear scaling\n",
        "    land_vacant = rasterio.open('/Users/richy/Downloads/Classes/Spring_2025/1.020/Project/doi_10_5061_dryad_np5hqbzq9__v20201008/places_fmv_pnas_dryad/1 estimates/places_fmv_vacant.tif')\n",
        "    land_data_np = land_vacant.read(1)\n",
        "    land_vacant.close()\n",
        "\n",
        "    land_data_np = np.where(land_data_np != 0, np.exp(land_data_np), 0) # transform the data to 2017$/hectare\n",
        "    land_data_np = land_data_np/acre_to_hectare # transform the data to 2017$/acre\n",
        "\n",
        "    # save back to tif\n",
        "    with rasterio.open('/Users/richy/Downloads/Classes/Spring_2025/1.020/Project/doi_10_5061_dryad_np5hqbzq9__v20201008/places_fmv_pnas_dryad/1 estimates/land_cost_linear.tif', 'r+') as f:\n",
        "        f.write(land_data_np, indexes=1)\n",
        "\n",
        "    f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# now, we resample the raster first to avoid high compute times: Raster > Projections > Warp (Reproject). We resample using median, so that we can account for/ignore outliers: really expensive pieces of land (ex. Manhattan).\n",
        "# we then convert raster to polygon using QGIS. Raster > Conversion > Polygonize (Raster to Vector)\n",
        "\n",
        "# import the converted polygon file\n",
        "land_costs_shp = gpd.read_file('/Users/richy/Downloads/Classes/Spring_2025/1.020/1.020-Data-Center-Project/data/data_siting/doi_10_5061_dryad_np5hqbzq9__v20201008/places_fmv_pnas_dryad/1 estimates/land_cost_linear_10000x10000.shp')\n",
        "land_costs_shp.to_crs('EPSG:5070', inplace=True)\n",
        "land_costs_shp_az = land_costs_shp[land_costs_shp.intersects(arizona.iloc[0,-1])]\n",
        "\n",
        "# NOTE: to increase accuracy, make sure to account for public land and Native American land. https://www.pnas.org/doi/10.1073/pnas.2012865117"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# compute estimated land costs in each HUC8\n",
        "# takes around 40 seconds to run. if desired, can even upscale the resolution further (to 20000x20000?)\n",
        "pixel_to_huc_land_cost = resolve_regions(land_costs_shp, huc_subbasins_az, 'DN', 'HUC8_y')\n",
        "pixel_to_huc_land_cost.convert_regions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# requirement for acres of land: https://www.jll.com/en-us/insights/how-to-assess-a-propertys-data-center-potential#:~:text=Data%20centers%20built%20for%20AI,multiple%20power%20substations%20on%20site.\n",
        "# lets say 1 GW = 1000MW requires 500 acres. So each MW requires 0.5 acres.\n",
        "\n",
        "# let's say data centers have a lifespan of 20 years: https://www.datacenterdynamics.com/en/analysis/the-data-center-life-story/.\n",
        "\n",
        "# time to convert everything to the right units...\n",
        "\n",
        "# WSF_1MW_DC: (m^3-eq water/MWh) * (24h/day) * (365.25day/year) * 20 year * 1MW = 24 * 365.25 * 20 multiplying factor\n",
        "# CF_1MW_DC: (kg-eq CO2/MWh) * (24h/day) * (365.25day/year) * 20 year * 1MW = 24 * 365.25 * 20 multiplying factor\n",
        "# elec_price: ($/MWh) * (24h/day) * (365.25day/year) * 20 year * 1MW = 24 * 365.25 * 20 multiplying factor\n",
        "# land price: ($/acre) * (0.5acre/MW) * 1 MW = 0.5 multiplying factor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "hours_multiplying = 24 * 365.25 * 20 # hours/day * days/year * years lifespan\n",
        "land_multiplying = 0.5 # 0.5 acre/MW\n",
        "\n",
        "# huc_subbasins_az['WSF_1MW_DC'] = huc_subbasins_az['WSF_1MW_DC'] * hours_multiplying # we could do this for water stress factor and carbon factor, but no need technically\n",
        "# huc_subbasins_az['CF_1MW_DC'] = huc_subbasins_az['CF_1MW_DC'] * hours_multiplying\n",
        "huc_subbasins_az['elec_price'] = huc_subbasins_az['elec_price'] * hours_multiplying\n",
        "huc_subbasins_az['DN'] = huc_subbasins_az['DN'] * land_multiplying\n",
        "\n",
        "huc_subbasins_az['tot_price'] = huc_subbasins_az['elec_price'] + huc_subbasins_az['DN']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# take a look at water stress factor, carbon factor data\n",
        "# wsf_dict = {k: v for k, v in zip(huc_subbasins_az['HUC8_y'], huc_subbasins_az['WSF_1MW_DC'])}\n",
        "# cf_dict = {k: v for k, v in zip(huc_subbasins_az['HUC8_y'], huc_subbasins_az['CF_1MW_DC'])}\n",
        "\n",
        "s_max = huc_subbasins_az['WSF_1MW_DC'].max()\n",
        "eplp_max = huc_subbasins_az['tot_price'].max()\n",
        "e_max = huc_subbasins_az['CF_1MW_DC'].max()\n",
        "\n",
        "# normalize variables\n",
        "\n",
        "huc_subbasins_az['WSF_1MW_DC_normalize'] = huc_subbasins_az['WSF_1MW_DC']/s_max\n",
        "huc_subbasins_az['tot_price_normalize'] = huc_subbasins_az['tot_price']/eplp_max\n",
        "huc_subbasins_az['CF_1MW_DC_normalize'] = huc_subbasins_az['CF_1MW_DC']/e_max"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "Cannot save file into a non-existent directory: '/data/data_siting'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# save gathered data values\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mhuc_subbasins_az\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/data/data_siting/huc_AZ_data.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3965\u001b[0m )\n\u001b[0;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/formats/format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/formats/csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    268\u001b[0m     )\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '/data/data_siting'"
          ]
        }
      ],
      "source": [
        "# save gathered data values\n",
        "huc_subbasins_az.to_csv(\"/data/data_siting/huc_AZ_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# functionalize visualization of different statistics\n",
        "\n",
        "def visualize_stats(df, col, title, cmap, cmap_label, ax=None):\n",
        "    \"\"\" \n",
        "    Visualization of selected statistics on HUC8 subbasins.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        df: geopandas.GeoDataFrame\n",
        "            GeoDataFrame to visualize\n",
        "        col: column \n",
        "            Column of GeoDataFrame for colors\n",
        "        title: string\n",
        "            Title of map\n",
        "        cmap: string\n",
        "            Color map to use\n",
        "        cmap_label: string\n",
        "            Label of color bar\n",
        "        ax: matplotlib.axes.Axes\n",
        "            Axis to plot the map on.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        ax: matplotlib.axes.Axes\n",
        "            Axis with the plotted figure\n",
        "    \"\"\"\n",
        "\n",
        "    _ = df.plot(column=col, cmap=cmap, legend=True, legend_kwds={\"label\": cmap_label})\n",
        "\n",
        "    ax.set_title(title)\n",
        "\n",
        "    return ax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Implement HUC8 Optimization Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import relevant data\n",
        "ghi_subbasin = pd.read_csv(\"data/data_siting/GHI_subbasin_AZ_per_watt.csv\", index_col=0).values\n",
        "wind_subbasin = pd.read_csv(\"data/data_siting/wind_power_per_watt_daily.csv\", index_col=0).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([16., 21., 16.,  7.,  2.,  2.,  6.,  7.,  5.,  2.]),\n",
              " array([0.04665005, 0.14198504, 0.23732004, 0.33265503, 0.42799003,\n",
              "        0.52332502, 0.61866002, 0.71399501, 0.80933001, 0.904665  ,\n",
              "        1.        ]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.hist(huc_subbasins_az['WSF_1MW_DC_normalize'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([42.,  4., 12.,  3.,  3., 12.,  3.,  2.,  1.,  2.]),\n",
              " array([0.74997558, 0.77497803, 0.79998047, 0.82498291, 0.84998535,\n",
              "        0.87498779, 0.89999023, 0.92499268, 0.94999512, 0.97499756,\n",
              "        1.        ]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.hist(huc_subbasins_az['tot_price_normalize'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([14.,  1.,  1.,  8., 19.,  0.,  4., 32.,  3.,  2.]),\n",
              " array([0.19133688, 0.27220319, 0.3530695 , 0.43393582, 0.51480213,\n",
              "        0.59566844, 0.67653475, 0.75740106, 0.83826738, 0.91913369,\n",
              "        1.        ]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.hist(huc_subbasins_az['CF_1MW_DC_normalize'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (mac64[arm] - Darwin 24.4.0 24E263)\n",
            "\n",
            "CPU model: Apple M1 Pro\n",
            "Thread count: 10 physical cores, 10 logical processors, using up to 10 threads\n",
            "\n",
            "Optimize a model with 468 rows, 618 columns and 61469 nonzeros\n",
            "Model fingerprint: 0x6b5757f1\n",
            "Coefficient statistics:\n",
            "  Matrix range     [1e-02, 9e+03]\n",
            "  Objective range  [1e-06, 5e-01]\n",
            "  Bounds range     [0e+00, 0e+00]\n",
            "  RHS range        [1e+02, 3e+04]\n",
            "Presolve removed 100 rows and 224 columns\n",
            "Presolve time: 0.02s\n",
            "Presolved: 368 rows, 394 columns, 10477 nonzeros\n",
            "\n",
            "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
            "       0    1.0861463e+02   1.683104e+04   0.000000e+00      0s\n",
            "     185    1.0876279e+02   0.000000e+00   0.000000e+00      0s\n",
            "\n",
            "Solved in 185 iterations and 0.02 seconds (0.04 work units)\n",
            "Optimal objective  1.087627916e+02\n"
          ]
        }
      ],
      "source": [
        "# huc8 list\n",
        "huc8_iter = huc_subbasins_az['HUC8_y']\n",
        "\n",
        "# set index for dataframe\n",
        "huc_subbasins_az.set_index(huc8_iter, inplace=True)\n",
        "\n",
        "# implement optimization model\n",
        "\n",
        "# number of MW required to add\n",
        "add_req = 100\n",
        "\n",
        "# weights for the objective function\n",
        "weights = {\n",
        "    'WSF_1MW_DC_normalize': 0.5, # because we normalize our values, which I think makes sense, we should inflate this more; there is more variation in WSF than land price, for example, which makes land price more consequential if we did comparable scaling factors. I guess that's a design choice.\n",
        "    'tot_price_normalize': 0.1,\n",
        "    'CF_1MW_DC_normalize': 0.5,\n",
        "}\n",
        "\n",
        "# normalization, maximum values\n",
        "max_vals = {\n",
        "    'WSF_1MW_DC_normalize': s_max,\n",
        "    'tot_price_normalize': eplp_max,\n",
        "    'CF_1MW_DC_normalize': e_max\n",
        "}\n",
        "\n",
        "model = gp.Model(\"AddDataCenters\")\n",
        "\n",
        "# decision variables: \n",
        "x = dict() # amount of datacenter MW to put in each HUC8 subbasin\n",
        "s = dict() # amount of solar MW to put in each HUC8 subbasin\n",
        "w = dict() # amount of wind MW to put in each HUC8 subbasin\n",
        "deficit = dict() # amount of energy deficit per day\n",
        "\n",
        "for huc8_code in huc8_iter:\n",
        "    x[huc8_code] = model.addVar(lb=0, name=f\"x_{huc8_code}\")\n",
        "    s[huc8_code] = model.addVar(lb=0, name=f\"s_{huc8_code}\")\n",
        "    w[huc8_code] = model.addVar(lb=0, name=f\"w_{huc8_code}\")\n",
        "\n",
        "for day in range(365):\n",
        "    deficit[day] = model.addVar(lb=0, name=f\"deficit_{day}\")\n",
        "\n",
        "\n",
        "\n",
        "# another decision variable: maximum water stress in any subbasin\n",
        "basin_max = model.addVar(lb=0, name=\"basin_max\")\n",
        "\n",
        "# develop objective\n",
        "obj = gp.LinExpr()\n",
        "\n",
        "# location summation costs\n",
        "for huc8_code in huc8_iter:\n",
        "    for key in weights.keys():\n",
        "        obj += x[huc8_code]*(weights[key]*(huc_subbasins_az.loc[huc8_code, key]/max_vals[key]))\n",
        "\n",
        "# maximum water stress cost\n",
        "obj += basin_max/s_max\n",
        "\n",
        "# overall deficit cost\n",
        "obj += gp.quicksum(deficit[day] for day in range(365))/(100*24*365)\n",
        "\n",
        "model.setObjective(obj, GRB.MINIMIZE)\n",
        "\n",
        "# add in the constraints\n",
        "\n",
        "# basin_max is at least the water stress in any subbasin\n",
        "for huc6_code, huc8_components in huc6_huc8_dict.items():\n",
        "    # consider existing data centers\n",
        "    model.addConstr(basin_max >= gp.quicksum((x[int(huc8_code)]+huc_subbasins_az.loc[int(huc8_code), 'existing_MW'])*huc_subbasins_az.loc[int(huc8_code), 'WSF_1MW_DC'] for huc8_code in huc8_components), name=f\"basin_max_{huc6_code}\")\n",
        "\n",
        "# add sufficient data center load\n",
        "model.addConstr(gp.quicksum(x[huc8_code] for huc8_code in huc8_iter) == add_req, name=\"add_req\")\n",
        "\n",
        "# add sufficient solar and wind capacity\n",
        "for idx, huc8_code in enumerate(huc8_iter):\n",
        "    model.addConstr(gp.quicksum(s[huc8_code]*ghi_subbasin[day, idx] for day in range(365)) + gp.quicksum(w[huc8_code]*wind_subbasin[day, idx] for day in range(365)) == 365*24*x[huc8_code], name=f\"renewables_{huc8_code}\")\n",
        "\n",
        "# penalize the deficit\n",
        "for day in range(365):\n",
        "    model.addConstr(deficit[day] >= 100*24 - gp.quicksum((s[huc8_code]*ghi_subbasin[day, idx] + w[huc8_code]*wind_subbasin[day, idx]) for idx, huc8_code in enumerate(huc8_iter)), name=f\"deficit_constr_{day}\")\n",
        "\n",
        "# optimize!\n",
        "model.optimize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_15080200 = 0.0\n",
            "s_15080200 = 0.0\n",
            "w_15080200 = 0.0\n",
            "x_15050202 = 0.0\n",
            "s_15050202 = 0.0\n",
            "w_15050202 = 0.0\n",
            "x_15050301 = 0.0\n",
            "s_15050301 = 0.0\n",
            "w_15050301 = 0.0\n",
            "x_15050302 = 0.0\n",
            "s_15050302 = 0.0\n",
            "w_15050302 = 0.0\n",
            "x_15050304 = 0.0\n",
            "s_15050304 = 0.0\n",
            "w_15050304 = 0.0\n",
            "x_15050305 = 0.0\n",
            "s_15050305 = 0.0\n",
            "w_15050305 = 0.0\n",
            "x_15050203 = 0.0\n",
            "s_15050203 = 0.0\n",
            "w_15050203 = 0.0\n",
            "x_15050306 = 0.0\n",
            "s_15050306 = 0.0\n",
            "w_15050306 = 0.0\n",
            "x_15050303 = 0.0\n",
            "s_15050303 = 0.0\n",
            "w_15050303 = 0.0\n",
            "x_15050100 = 0.0\n",
            "s_15050100 = 0.0\n",
            "w_15050100 = 0.0\n",
            "x_15080301 = 0.0\n",
            "s_15080301 = 0.0\n",
            "w_15080301 = 0.0\n",
            "x_15080302 = 0.0\n",
            "s_15080302 = 0.0\n",
            "w_15080302 = 0.0\n",
            "x_15040003 = 0.0\n",
            "s_15040003 = 0.0\n",
            "w_15040003 = 0.0\n",
            "x_15040006 = 0.0\n",
            "s_15040006 = 0.0\n",
            "w_15040006 = 0.0\n",
            "x_15050201 = 0.0\n",
            "s_15050201 = 0.0\n",
            "w_15050201 = 0.0\n",
            "x_15040002 = 0.0\n",
            "s_15040002 = 0.0\n",
            "w_15040002 = 0.0\n",
            "x_15040005 = 0.0\n",
            "s_15040005 = 0.0\n",
            "w_15040005 = 0.0\n",
            "x_15040004 = 0.0\n",
            "s_15040004 = 0.0\n",
            "w_15040004 = 0.0\n",
            "x_15060101 = 0.0\n",
            "s_15060101 = 0.0\n",
            "w_15060101 = 0.0\n",
            "x_15060102 = 0.0\n",
            "s_15060102 = 0.0\n",
            "w_15060102 = 0.0\n",
            "x_15080102 = 0.0\n",
            "s_15080102 = 0.0\n",
            "w_15080102 = 0.0\n",
            "x_15080101 = 0.0\n",
            "s_15080101 = 0.0\n",
            "w_15080101 = 0.0\n",
            "x_15080103 = 0.0\n",
            "s_15080103 = 0.0\n",
            "w_15080103 = 0.0\n",
            "x_15030108 = 0.0\n",
            "s_15030108 = 0.0\n",
            "w_15030108 = 0.0\n",
            "x_15070203 = 0.0\n",
            "s_15070203 = 0.0\n",
            "w_15070203 = 0.0\n",
            "x_15070202 = 0.0\n",
            "s_15070202 = 0.0\n",
            "w_15070202 = 0.0\n",
            "x_15030107 = 100.0\n",
            "s_15030107 = 349.2083082287082\n",
            "w_15030107 = 69.35346200883798\n",
            "x_15070201 = 0.0\n",
            "s_15070201 = 0.0\n",
            "w_15070201 = 0.0\n",
            "x_15070101 = 0.0\n",
            "s_15070101 = 0.0\n",
            "w_15070101 = 0.0\n",
            "x_15070104 = 0.0\n",
            "s_15070104 = 0.0\n",
            "w_15070104 = 0.0\n",
            "x_15040007 = 0.0\n",
            "s_15040007 = 0.0\n",
            "w_15040007 = 0.0\n",
            "x_15060106 = 0.0\n",
            "s_15060106 = 0.0\n",
            "w_15060106 = 0.0\n",
            "x_15060103 = 0.0\n",
            "s_15060103 = 0.0\n",
            "w_15060103 = 0.0\n",
            "x_15060105 = 0.0\n",
            "s_15060105 = 0.0\n",
            "w_15060105 = 0.0\n",
            "x_15070102 = 0.0\n",
            "s_15070102 = 0.0\n",
            "w_15070102 = 0.0\n",
            "x_15060203 = 0.0\n",
            "s_15060203 = 0.0\n",
            "w_15060203 = 0.0\n",
            "x_15020010 = 0.0\n",
            "s_15020010 = 0.0\n",
            "w_15020010 = 0.0\n",
            "x_15020008 = 0.0\n",
            "s_15020008 = 0.0\n",
            "w_15020008 = 0.0\n",
            "x_15060202 = 0.0\n",
            "s_15060202 = 0.0\n",
            "w_15060202 = 0.0\n",
            "x_15020015 = 0.0\n",
            "s_15020015 = 0.0\n",
            "w_15020015 = 0.0\n",
            "x_15020001 = 0.0\n",
            "s_15020001 = 0.0\n",
            "w_15020001 = 0.0\n",
            "x_15060104 = 0.0\n",
            "s_15060104 = 0.0\n",
            "w_15060104 = 0.0\n",
            "x_15020003 = 0.0\n",
            "s_15020003 = 0.0\n",
            "w_15020003 = 0.0\n",
            "x_15020005 = 0.0\n",
            "s_15020005 = 0.0\n",
            "w_15020005 = 0.0\n",
            "x_15020002 = 0.0\n",
            "s_15020002 = 0.0\n",
            "w_15020002 = 0.0\n",
            "x_15020004 = 0.0\n",
            "s_15020004 = 0.0\n",
            "w_15020004 = 0.0\n",
            "x_15020007 = 0.0\n",
            "s_15020007 = 0.0\n",
            "w_15020007 = 0.0\n",
            "x_15020009 = 0.0\n",
            "s_15020009 = 0.0\n",
            "w_15020009 = 0.0\n",
            "x_15020011 = 0.0\n",
            "s_15020011 = 0.0\n",
            "w_15020011 = 0.0\n",
            "x_15020006 = 0.0\n",
            "s_15020006 = 0.0\n",
            "w_15020006 = 0.0\n",
            "x_15030106 = 0.0\n",
            "s_15030106 = 0.0\n",
            "w_15030106 = 0.0\n",
            "x_15070103 = 0.0\n",
            "s_15070103 = 0.0\n",
            "w_15070103 = 0.0\n",
            "x_15030104 = 0.0\n",
            "s_15030104 = 0.0\n",
            "w_15030104 = 0.0\n",
            "x_15030105 = 0.0\n",
            "s_15030105 = 0.0\n",
            "w_15030105 = 0.0\n",
            "x_15030204 = 0.0\n",
            "s_15030204 = 0.0\n",
            "w_15030204 = 0.0\n",
            "x_15030203 = 0.0\n",
            "s_15030203 = 0.0\n",
            "w_15030203 = 0.0\n",
            "x_15030202 = 0.0\n",
            "s_15030202 = 0.0\n",
            "w_15030202 = 0.0\n",
            "x_15030201 = 0.0\n",
            "s_15030201 = 0.0\n",
            "w_15030201 = 0.0\n",
            "x_15030103 = 0.0\n",
            "s_15030103 = 0.0\n",
            "w_15030103 = 0.0\n",
            "x_15060201 = 0.0\n",
            "s_15060201 = 0.0\n",
            "w_15060201 = 0.0\n",
            "x_15030101 = 0.0\n",
            "s_15030101 = 0.0\n",
            "w_15030101 = 0.0\n",
            "x_15010007 = 0.0\n",
            "s_15010007 = 0.0\n",
            "w_15010007 = 0.0\n",
            "x_15010014 = 0.0\n",
            "s_15010014 = 0.0\n",
            "w_15010014 = 0.0\n",
            "x_15010002 = 0.0\n",
            "s_15010002 = 0.0\n",
            "w_15010002 = 0.0\n",
            "x_15010005 = 0.0\n",
            "s_15010005 = 0.0\n",
            "w_15010005 = 0.0\n",
            "x_15010006 = 0.0\n",
            "s_15010006 = 0.0\n",
            "w_15010006 = 0.0\n",
            "x_15010009 = 0.0\n",
            "s_15010009 = 0.0\n",
            "w_15010009 = 0.0\n",
            "x_15010010 = 0.0\n",
            "s_15010010 = 0.0\n",
            "w_15010010 = 0.0\n",
            "x_15020014 = 0.0\n",
            "s_15020014 = 0.0\n",
            "w_15020014 = 0.0\n",
            "x_15020013 = 0.0\n",
            "s_15020013 = 0.0\n",
            "w_15020013 = 0.0\n",
            "x_14080106 = 0.0\n",
            "s_14080106 = 0.0\n",
            "w_14080106 = 0.0\n",
            "x_15020012 = 0.0\n",
            "s_15020012 = 0.0\n",
            "w_15020012 = 0.0\n",
            "x_14080204 = 0.0\n",
            "s_14080204 = 0.0\n",
            "w_14080204 = 0.0\n",
            "x_14080105 = 0.0\n",
            "s_14080105 = 0.0\n",
            "w_14080105 = 0.0\n",
            "x_14080205 = 0.0\n",
            "s_14080205 = 0.0\n",
            "w_14080205 = 0.0\n",
            "x_14080201 = 0.0\n",
            "s_14080201 = 0.0\n",
            "w_14080201 = 0.0\n",
            "x_15020016 = 0.0\n",
            "s_15020016 = 0.0\n",
            "w_15020016 = 0.0\n",
            "x_15020017 = 0.0\n",
            "s_15020017 = 0.0\n",
            "w_15020017 = 0.0\n",
            "x_15010004 = 0.0\n",
            "s_15010004 = 0.0\n",
            "w_15010004 = 0.0\n",
            "x_15020018 = 0.0\n",
            "s_15020018 = 0.0\n",
            "w_15020018 = 0.0\n",
            "x_15010001 = 0.0\n",
            "s_15010001 = 0.0\n",
            "w_15010001 = 0.0\n",
            "x_14070006 = 0.0\n",
            "s_14070006 = 0.0\n",
            "w_14070006 = 0.0\n",
            "x_15010003 = 0.0\n",
            "s_15010003 = 0.0\n",
            "w_15010003 = 0.0\n",
            "x_14070007 = 0.0\n",
            "s_14070007 = 0.0\n",
            "w_14070007 = 0.0\n",
            "deficit_0 = 1038.9438884252004\n",
            "deficit_1 = 906.8425799801618\n",
            "deficit_2 = 729.1365497857693\n",
            "deficit_3 = 1086.6291454211855\n",
            "deficit_4 = 1119.4531337253272\n",
            "deficit_5 = 1045.2924880087417\n",
            "deficit_6 = 378.49661070444716\n",
            "deficit_7 = 938.699321636512\n",
            "deficit_8 = 994.369643829929\n",
            "deficit_9 = 334.26978301879484\n",
            "deficit_10 = 0.0\n",
            "deficit_11 = 1368.438696555863\n",
            "deficit_12 = 1047.2483046185453\n",
            "deficit_13 = 478.2619016524225\n",
            "deficit_14 = 886.78735899903\n",
            "deficit_15 = 1070.8949725611496\n",
            "deficit_16 = 815.3447320671104\n",
            "deficit_17 = 1004.6693662792654\n",
            "deficit_18 = 974.6410218434147\n",
            "deficit_19 = 946.7905751934342\n",
            "deficit_20 = 908.9318552047604\n",
            "deficit_21 = 991.1190804512767\n",
            "deficit_22 = 1382.8431413352794\n",
            "deficit_23 = 1745.176232321329\n",
            "deficit_24 = 1497.023281138338\n",
            "deficit_25 = 1625.6573315995274\n",
            "deficit_26 = 1201.3379668401788\n",
            "deficit_27 = 670.5430976341173\n",
            "deficit_28 = 329.19218662663707\n",
            "deficit_29 = 850.5841085592925\n",
            "deficit_30 = 884.811238766035\n",
            "deficit_31 = 877.1025678146037\n",
            "deficit_32 = 1145.3834905309666\n",
            "deficit_33 = 1975.6325796631563\n",
            "deficit_34 = 793.8642667525346\n",
            "deficit_35 = 806.0312506896785\n",
            "deficit_36 = 848.7956323662403\n",
            "deficit_37 = 179.07255081733288\n",
            "deficit_38 = 0.0\n",
            "deficit_39 = 716.7745573681386\n",
            "deficit_40 = 1023.9927306595916\n",
            "deficit_41 = 996.5211557158096\n",
            "deficit_42 = 478.4714340319938\n",
            "deficit_43 = 679.1014570489261\n",
            "deficit_44 = 474.8746981656957\n",
            "deficit_45 = 34.18323362878028\n",
            "deficit_46 = 507.7966847636332\n",
            "deficit_47 = 0.0\n",
            "deficit_48 = 167.69926043865695\n",
            "deficit_49 = 0.0\n",
            "deficit_50 = 946.5177551755463\n",
            "deficit_51 = 946.0813611363519\n",
            "deficit_52 = 539.2890013222376\n",
            "deficit_53 = 102.10350148822359\n",
            "deficit_54 = 0.0\n",
            "deficit_55 = 146.12604951027805\n",
            "deficit_56 = 0.0\n",
            "deficit_57 = 161.8452385599089\n",
            "deficit_58 = 270.64333741961616\n",
            "deficit_59 = 207.80452421460024\n",
            "deficit_60 = 187.25939383388095\n",
            "deficit_61 = 689.3824914386541\n",
            "deficit_62 = 0.0\n",
            "deficit_63 = 125.2503787266741\n",
            "deficit_64 = 0.0\n",
            "deficit_65 = 0.0\n",
            "deficit_66 = 398.9586453481523\n",
            "deficit_67 = 734.0523074674844\n",
            "deficit_68 = 0.0\n",
            "deficit_69 = 214.72022436949823\n",
            "deficit_70 = 139.85458774384134\n",
            "deficit_71 = 28.33808556907278\n",
            "deficit_72 = 133.8599391203319\n",
            "deficit_73 = 449.2170506830163\n",
            "deficit_74 = 1022.2068587798318\n",
            "deficit_75 = 0.0\n",
            "deficit_76 = 0.0\n",
            "deficit_77 = 27.78460644858275\n",
            "deficit_78 = 60.119849015287976\n",
            "deficit_79 = 0.0\n",
            "deficit_80 = 0.0\n",
            "deficit_81 = 0.0\n",
            "deficit_82 = 0.0\n",
            "deficit_83 = 0.0\n",
            "deficit_84 = 0.0\n",
            "deficit_85 = 110.83242135245109\n",
            "deficit_86 = 5.798367833478114\n",
            "deficit_87 = 0.0\n",
            "deficit_88 = 599.0420583461901\n",
            "deficit_89 = 0.0\n",
            "deficit_90 = 0.0\n",
            "deficit_91 = 401.3960374507067\n",
            "deficit_92 = 0.0\n",
            "deficit_93 = 0.0\n",
            "deficit_94 = 0.0\n",
            "deficit_95 = 0.0\n",
            "deficit_96 = 0.0\n",
            "deficit_97 = 446.89574940239925\n",
            "deficit_98 = 260.74378122624273\n",
            "deficit_99 = 0.0\n",
            "deficit_100 = 309.88961655726354\n",
            "deficit_101 = 0.0\n",
            "deficit_102 = 0.0\n",
            "deficit_103 = 0.0\n",
            "deficit_104 = 0.0\n",
            "deficit_105 = 0.0\n",
            "deficit_106 = 0.0\n",
            "deficit_107 = 0.0\n",
            "deficit_108 = 0.0\n",
            "deficit_109 = 0.0\n",
            "deficit_110 = 0.0\n",
            "deficit_111 = 0.0\n",
            "deficit_112 = 0.0\n",
            "deficit_113 = 0.0\n",
            "deficit_114 = 0.0\n",
            "deficit_115 = 0.0\n",
            "deficit_116 = 0.0\n",
            "deficit_117 = 0.0\n",
            "deficit_118 = 0.0\n",
            "deficit_119 = 0.0\n",
            "deficit_120 = 0.0\n",
            "deficit_121 = 0.0\n",
            "deficit_122 = 0.0\n",
            "deficit_123 = 0.0\n",
            "deficit_124 = 0.0\n",
            "deficit_125 = 0.0\n",
            "deficit_126 = 0.0\n",
            "deficit_127 = 0.0\n",
            "deficit_128 = 0.0\n",
            "deficit_129 = 0.0\n",
            "deficit_130 = 0.0\n",
            "deficit_131 = 0.0\n",
            "deficit_132 = 0.0\n",
            "deficit_133 = 0.0\n",
            "deficit_134 = 0.0\n",
            "deficit_135 = 0.0\n",
            "deficit_136 = 0.0\n",
            "deficit_137 = 0.0\n",
            "deficit_138 = 0.0\n",
            "deficit_139 = 0.0\n",
            "deficit_140 = 0.0\n",
            "deficit_141 = 0.0\n",
            "deficit_142 = 0.0\n",
            "deficit_143 = 0.0\n",
            "deficit_144 = 0.0\n",
            "deficit_145 = 0.0\n",
            "deficit_146 = 0.0\n",
            "deficit_147 = 0.0\n",
            "deficit_148 = 0.0\n",
            "deficit_149 = 0.0\n",
            "deficit_150 = 0.0\n",
            "deficit_151 = 0.0\n",
            "deficit_152 = 0.0\n",
            "deficit_153 = 0.0\n",
            "deficit_154 = 0.0\n",
            "deficit_155 = 0.0\n",
            "deficit_156 = 0.0\n",
            "deficit_157 = 0.0\n",
            "deficit_158 = 0.0\n",
            "deficit_159 = 0.0\n",
            "deficit_160 = 0.0\n",
            "deficit_161 = 0.0\n",
            "deficit_162 = 0.0\n",
            "deficit_163 = 0.0\n",
            "deficit_164 = 0.0\n",
            "deficit_165 = 0.0\n",
            "deficit_166 = 0.0\n",
            "deficit_167 = 0.0\n",
            "deficit_168 = 0.0\n",
            "deficit_169 = 0.0\n",
            "deficit_170 = 0.0\n",
            "deficit_171 = 0.0\n",
            "deficit_172 = 0.0\n",
            "deficit_173 = 0.0\n",
            "deficit_174 = 0.0\n",
            "deficit_175 = 0.0\n",
            "deficit_176 = 0.0\n",
            "deficit_177 = 0.0\n",
            "deficit_178 = 0.0\n",
            "deficit_179 = 0.0\n",
            "deficit_180 = 0.0\n",
            "deficit_181 = 0.0\n",
            "deficit_182 = 0.0\n",
            "deficit_183 = 0.0\n",
            "deficit_184 = 0.0\n",
            "deficit_185 = 0.0\n",
            "deficit_186 = 343.4526388405955\n",
            "deficit_187 = 0.0\n",
            "deficit_188 = 0.0\n",
            "deficit_189 = 0.0\n",
            "deficit_190 = 0.0\n",
            "deficit_191 = 0.0\n",
            "deficit_192 = 0.0\n",
            "deficit_193 = 0.0\n",
            "deficit_194 = 0.0\n",
            "deficit_195 = 0.0\n",
            "deficit_196 = 389.58174986949973\n",
            "deficit_197 = 106.92396668238875\n",
            "deficit_198 = 0.0\n",
            "deficit_199 = 0.0\n",
            "deficit_200 = 0.0\n",
            "deficit_201 = 8.053882475862283\n",
            "deficit_202 = 0.0\n",
            "deficit_203 = 0.0\n",
            "deficit_204 = 0.0\n",
            "deficit_205 = 0.0\n",
            "deficit_206 = 0.0\n",
            "deficit_207 = 306.77859986727054\n",
            "deficit_208 = 136.01070640212745\n",
            "deficit_209 = 0.0\n",
            "deficit_210 = 0.0\n",
            "deficit_211 = 0.0\n",
            "deficit_212 = 0.0\n",
            "deficit_213 = 0.0\n",
            "deficit_214 = 0.0\n",
            "deficit_215 = 484.90966775757846\n",
            "deficit_216 = 0.0\n",
            "deficit_217 = 1209.5070055344468\n",
            "deficit_218 = 74.14964167298224\n",
            "deficit_219 = 0.0\n",
            "deficit_220 = 0.0\n",
            "deficit_221 = 0.0\n",
            "deficit_222 = 0.0\n",
            "deficit_223 = 0.0\n",
            "deficit_224 = 0.0\n",
            "deficit_225 = 0.0\n",
            "deficit_226 = 2.0438426152298663\n",
            "deficit_227 = 0.0\n",
            "deficit_228 = 170.76208248027757\n",
            "deficit_229 = 0.0\n",
            "deficit_230 = 0.0\n",
            "deficit_231 = 0.0\n",
            "deficit_232 = 1025.1871278353485\n",
            "deficit_233 = 131.65950145781258\n",
            "deficit_234 = 205.40496102370514\n",
            "deficit_235 = 205.93426580095397\n",
            "deficit_236 = 1339.954716236009\n",
            "deficit_237 = 92.97214447661986\n",
            "deficit_238 = 0.0\n",
            "deficit_239 = 0.0\n",
            "deficit_240 = 44.28107997377105\n",
            "deficit_241 = 266.5025445103802\n",
            "deficit_242 = 775.0678650772322\n",
            "deficit_243 = 0.0\n",
            "deficit_244 = 0.0\n",
            "deficit_245 = 0.0\n",
            "deficit_246 = 0.0\n",
            "deficit_247 = 0.0\n",
            "deficit_248 = 0.0\n",
            "deficit_249 = 58.109575171598195\n",
            "deficit_250 = 1030.2849823773665\n",
            "deficit_251 = 1360.033784682455\n",
            "deficit_252 = 326.1374584274301\n",
            "deficit_253 = 66.52106930721699\n",
            "deficit_254 = 0.0\n",
            "deficit_255 = 0.0\n",
            "deficit_256 = 0.0\n",
            "deficit_257 = 0.0\n",
            "deficit_258 = 0.0\n",
            "deficit_259 = 0.0\n",
            "deficit_260 = 0.0\n",
            "deficit_261 = 0.0\n",
            "deficit_262 = 0.0\n",
            "deficit_263 = 0.0\n",
            "deficit_264 = 0.0\n",
            "deficit_265 = 0.0\n",
            "deficit_266 = 0.0\n",
            "deficit_267 = 0.0\n",
            "deficit_268 = 0.0\n",
            "deficit_269 = 0.0\n",
            "deficit_270 = 0.0\n",
            "deficit_271 = 141.60744877296662\n",
            "deficit_272 = 177.45106517468315\n",
            "deficit_273 = 134.09932075256623\n",
            "deficit_274 = 0.0\n",
            "deficit_275 = 0.0\n",
            "deficit_276 = 0.0\n",
            "deficit_277 = 0.0\n",
            "deficit_278 = 99.18004715583842\n",
            "deficit_279 = 187.25903261866685\n",
            "deficit_280 = 0.0\n",
            "deficit_281 = 0.0\n",
            "deficit_282 = 198.2167580310857\n",
            "deficit_283 = 445.01352627525046\n",
            "deficit_284 = 173.9371722583947\n",
            "deficit_285 = 0.0\n",
            "deficit_286 = 378.0539159187687\n",
            "deficit_287 = 343.668377812488\n",
            "deficit_288 = 250.52763931746526\n",
            "deficit_289 = 563.1243020145326\n",
            "deficit_290 = 0.0\n",
            "deficit_291 = 535.1163362697433\n",
            "deficit_292 = 562.0333628563556\n",
            "deficit_293 = 0.0\n",
            "deficit_294 = 430.0534211652512\n",
            "deficit_295 = 409.43274210043\n",
            "deficit_296 = 648.0547343333525\n",
            "deficit_297 = 580.0171694069373\n",
            "deficit_298 = 618.5589853460884\n",
            "deficit_299 = 42.77207270845972\n",
            "deficit_300 = 0.0\n",
            "deficit_301 = 839.86723912801\n",
            "deficit_302 = 1281.2494602760785\n",
            "deficit_303 = 773.364311551425\n",
            "deficit_304 = 712.7762340542595\n",
            "deficit_305 = 409.898416520495\n",
            "deficit_306 = 85.77202472291437\n",
            "deficit_307 = 863.2378606121596\n",
            "deficit_308 = 205.8102924177257\n",
            "deficit_309 = 706.2192285505939\n",
            "deficit_310 = 690.8021460013312\n",
            "deficit_311 = 587.7050698477165\n",
            "deficit_312 = 917.8217721063417\n",
            "deficit_313 = 1271.707956113044\n",
            "deficit_314 = 646.9834415137593\n",
            "deficit_315 = 385.4159303760448\n",
            "deficit_316 = 468.13569137215745\n",
            "deficit_317 = 725.9374897337524\n",
            "deficit_318 = 235.32292330995156\n",
            "deficit_319 = 168.6817303928181\n",
            "deficit_320 = 909.95294615309\n",
            "deficit_321 = 1003.9654159265292\n",
            "deficit_322 = 982.269490757928\n",
            "deficit_323 = 2091.0394407430354\n",
            "deficit_324 = 1282.5996615955635\n",
            "deficit_325 = 953.1590250971033\n",
            "deficit_326 = 538.6271701910218\n",
            "deficit_327 = 1092.5727781235496\n",
            "deficit_328 = 930.4470584038033\n",
            "deficit_329 = 950.850995641134\n",
            "deficit_330 = 819.2738061821663\n",
            "deficit_331 = 1032.9425617185266\n",
            "deficit_332 = 1203.9085150205879\n",
            "deficit_333 = 1897.5224041997028\n",
            "deficit_334 = 2053.0615457747786\n",
            "deficit_335 = 1414.0448798897553\n",
            "deficit_336 = 81.58757429875509\n",
            "deficit_337 = 643.7477526350416\n",
            "deficit_338 = 1131.0773711856716\n",
            "deficit_339 = 1116.2133038773143\n",
            "deficit_340 = 419.0596510195242\n",
            "deficit_341 = 1216.1003001447073\n",
            "deficit_342 = 894.6905774101813\n",
            "deficit_343 = 1041.5516150086153\n",
            "deficit_344 = 802.8301343540548\n",
            "deficit_345 = 1290.0351076997315\n",
            "deficit_346 = 1421.1774375873845\n",
            "deficit_347 = 1074.1654444220608\n",
            "deficit_348 = 1229.0551071251477\n",
            "deficit_349 = 1236.8937497726833\n",
            "deficit_350 = 1315.434014079296\n",
            "deficit_351 = 1458.4631574802327\n",
            "deficit_352 = 126.75285535932535\n",
            "deficit_353 = 1557.9758090181158\n",
            "deficit_354 = 1461.2943697554933\n",
            "deficit_355 = 1130.6020623186935\n",
            "deficit_356 = 1242.0252499136038\n",
            "deficit_357 = 1013.0432111584948\n",
            "deficit_358 = 1056.705403898757\n",
            "deficit_359 = 1129.5790572082205\n",
            "deficit_360 = 1213.3108855238938\n",
            "deficit_361 = 1580.920891809911\n",
            "deficit_362 = 633.8515574526622\n",
            "deficit_363 = 1216.1838351046792\n",
            "deficit_364 = 1220.182257840822\n",
            "basin_max = 29887.378809965892\n"
          ]
        }
      ],
      "source": [
        "for v in model.getVars():\n",
        "    print(f\"{v.VarName} = {v.X}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "x5h-jYTzfz_g",
        "outputId": "37a189ed-20d4-4eaf-ca5e-449062417254"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created 129 baseline data centers\n",
            "Created 480 potential locations\n",
            "Starting optimization with 129 data centers and 480 potential locations\n",
            "Restricted license - for non-production use only - expires 2026-11-23\n",
            "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (linux64 - \"Ubuntu 22.04.4 LTS\")\n",
            "\n",
            "CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz, instruction set [SSE2|AVX|AVX2]\n",
            "Thread count: 1 physical cores, 2 logical processors, using up to 2 threads\n",
            "\n"
          ]
        },
        {
          "ename": "GurobiError",
          "evalue": "Model too large for size-limited license; visit https://gurobi.com/unrestricted for more information",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mGurobiError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-fa8e945795f4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0mmin_distance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m  \u001b[0;31m# km\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize_data_center_locations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline_centers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpotential_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_distance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-fa8e945795f4>\u001b[0m in \u001b[0;36moptimize_data_center_locations\u001b[0;34m(baseline_centers, potential_locations, min_distance)\u001b[0m\n\u001b[1;32m    345\u001b[0m                         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddConstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"min_dist_{d1}_{l1}_{d2}_{l2}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mGRB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMAL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msrc/gurobipy/_model.pyx\u001b[0m in \u001b[0;36mgurobipy._model.Model.optimize\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mGurobiError\u001b[0m: Model too large for size-limited license; visit https://gurobi.com/unrestricted for more information"
          ]
        }
      ],
      "source": [
        "# major cities for baseline data centers\n",
        "# basically, atm all of the data centers are in these three, so im approximating by just using their central lat/lon\n",
        "# count is how the 129 are split among the locations\n",
        "CITIES = {\n",
        "    \"Phoenix\": {\"lat\": 33.4484, \"lng\": -112.0740, \"count\": 121},\n",
        "    \"Tucson\": {\"lat\": 32.2226, \"lng\": -110.9747, \"count\": 7},\n",
        "    \"Nogales\": {\"lat\": 31.3405, \"lng\": -110.9420, \"count\": 1}\n",
        "}\n",
        "\n",
        "# create the baseline data centers locations\n",
        "def create_baseline_centers():\n",
        "    centers = []\n",
        "    center_id = 0\n",
        "\n",
        "    for city, info in CITIES.items():\n",
        "        # decided to add a slight random variation to prevent all centers being at exactly the same point\n",
        "        for i in range(info[\"count\"]):\n",
        "            #within ~5km of the city center\n",
        "            lat_variation = (np.random.random() - 0.5) * 0.05\n",
        "            lng_variation = (np.random.random() - 0.5) * 0.05\n",
        "\n",
        "            centers.append({\n",
        "                \"id\": center_id,\n",
        "                \"city\": city,\n",
        "                \"lat\": info[\"lat\"] + lat_variation,\n",
        "                \"lng\": info[\"lng\"] + lng_variation\n",
        "            })\n",
        "            center_id += 1\n",
        "\n",
        "    return centers\n",
        "\n",
        "# here, i made a grid of potential locations across the approximate Arizona\n",
        "def create_location_grid(resolution=0.2):\n",
        "    locations = []\n",
        "    loc_id = 0\n",
        "    for lat in np.arange(AZ_MIN_LAT, AZ_MAX_LAT + resolution, resolution):\n",
        "        for lng in np.arange(AZ_MIN_LNG, AZ_MAX_LNG + resolution, lng_spacing): # should this be resolution rather than lng_spacing? - RICHARD\n",
        "            locations.append({\n",
        "                \"id\": loc_id,\n",
        "                \"lat\": lat,\n",
        "                \"lng\": lng\n",
        "            })\n",
        "            loc_id += 1\n",
        "\n",
        "    return locations\n",
        "\n",
        "# generate water stress data based on the Aqueduct data approximately\n",
        "# will have to request the actual shapefiles for later on\n",
        "# so this is just simplified, with higher values = more stress (0-5 scale)\n",
        "def generate_water_stress(locations):\n",
        "\n",
        "    # northern Arizona: lower stress (more precipitation)\n",
        "    # central & Phoenix metro: high stress\n",
        "    # southern Arizona: very high stress\n",
        "    # western Arizona along colorado river: medium stress\n",
        "\n",
        "    for loc in locations:\n",
        "        lat, lng = loc[\"lat\"], loc[\"lng\"]\n",
        "        base_stress = 5.0 - (lat - AZ_MIN_LAT) / (AZ_MAX_LAT - AZ_MIN_LAT) * 2.5\n",
        "\n",
        "        # phoenix metro area: very high stress\n",
        "        if (33.0 <= lat <= 34.0) and (-112.5 <= lng <= -111.5):\n",
        "            stress = 4.5 + np.random.random() * 0.5  # 4.5-5.0\n",
        "\n",
        "        # tucson area: very high stress\n",
        "        elif (31.9 <= lat <= 32.5) and (-111.2 <= lng <= -110.7):\n",
        "            stress = 4.2 + np.random.random() * 0.8  # 4.2-5.0\n",
        "\n",
        "        # colorado river region: medium stress due to water access\n",
        "        elif lng < -113.5:\n",
        "            stress = 2.5 + np.random.random() * 1.5  # 2.5-4.0\n",
        "\n",
        "        # northern mountains (e.g., flagstaff): lower stress\n",
        "        elif (34.5 <= lat <= 36.0) and (-112.5 <= lng <= -111.0):\n",
        "            stress = 1.8 + np.random.random() * 1.2  # 1.8-3.0\n",
        "\n",
        "        #  northeastern AZ (like the navajo area): medium-high stress\n",
        "        elif lat > 35.0 and lng > -110.5:\n",
        "            stress = 3.2 + np.random.random() * 1.0  # 3.2-4.2\n",
        "\n",
        "        # if not near, we can just use base stress with some noise\n",
        "        else:\n",
        "            stress = base_stress + (np.random.random() - 0.5) * 1.0\n",
        "\n",
        "        stress = max(0, min(5, stress))\n",
        "        loc[\"water_stress\"] = stress\n",
        "\n",
        "    return locations\n",
        "\n",
        "#electricity price data by county\n",
        "\n",
        "# out of curiosity, where are the electricity prices sourced from? In case we want to reproduce\n",
        "# these electricity price calculations for other states, and I can help - RICHARD\n",
        "def generate_electricity_prices(locations):\n",
        "\n",
        "    # note: the average commercial electricity price in Arizona is ~$0.0811/kWh (8.11 cents)\n",
        "\n",
        "    for loc in locations:\n",
        "        lat, lng = loc[\"lat\"], loc[\"lng\"]\n",
        "        base_price = 0.0811\n",
        "\n",
        "        # phoenix metro area (APS & SRP territory)\n",
        "        if (33.0 <= lat <= 34.0) and (-112.5 <= lng <= -111.5):\n",
        "            if lng < -112.0:  # SRP territory\n",
        "                price = base_price * (0.92 + np.random.random() * 0.08)  # 8% lower on average\n",
        "            else:  # APS territory\n",
        "                price = base_price * (0.98 + np.random.random() * 0.07)  # 2% lower on average\n",
        "\n",
        "        # tucson area (tucson electric power)\n",
        "        elif (31.9 <= lat <= 32.5) and (-111.2 <= lng <= -110.7):\n",
        "            price = base_price * (1.03 + np.random.random() * 0.07)  # 3-10% higher\n",
        "\n",
        "        # rural areas (higher distribution costs)\n",
        "        elif lat > 35.0 or lat < 31.7 or lng < -113.0:\n",
        "            price = base_price * (1.10 + np.random.random() * 0.15)  # 10-25% higher\n",
        "\n",
        "        # otherwise, i use base price with some noise\n",
        "        else:\n",
        "            price = base_price * (0.95 + np.random.random() * 0.15)  # 10% variation\n",
        "\n",
        "        loc[\"electricity_price\"] = price\n",
        "\n",
        "    return locations\n",
        "\n",
        "# carbon emission rate data in tons Co2/'Mwh\n",
        "def generate_carbon_emissions(locations):\n",
        "\n",
        "    # avg emissions for arizona's grid: ~0.4 tons CO2/MWh (400 kg/MWh)\n",
        "    # from what i looked up, Palo Verde Nuclear Plant creates the biggest variation\n",
        "    # there's probably a better way to do this, but for the approximation, I just use the plant to vary this val plus some of the predominant plant type variation otherwise\n",
        "\n",
        "    for loc in locations:\n",
        "        lat, lng = loc[\"lat\"], loc[\"lng\"]\n",
        "\n",
        "        base_emissions = 0.40  # tons CO2 per MWh\n",
        "\n",
        "        # areas near Palo Verde Nuclear Generating Station (west of phoenix)\n",
        "        if (33.2 <= lat <= 33.5) and (-113.0 <= lng <= -112.5):\n",
        "            emissions = base_emissions * (0.65 + np.random.random() * 0.10)  # 25-35% lower\n",
        "\n",
        "        # phoenix metro area (mixed generation)\n",
        "        elif (33.0 <= lat <= 34.0) and (-112.5 <= lng <= -111.5):\n",
        "            emissions = base_emissions * (0.90 + np.random.random() * 0.15)  # 0-25% lower\n",
        "\n",
        "        # northeastern AZ (coal plants)\n",
        "        elif lat > 35.0 and lng > -110.5:\n",
        "            emissions = base_emissions * (1.20 + np.random.random() * 0.15)  # 20-35% higher\n",
        "\n",
        "        # southern AZ (more solar penetration)\n",
        "        elif lat < 32.5:\n",
        "            emissions = base_emissions * (0.85 + np.random.random() * 0.15)  # 0-30% lower\n",
        "\n",
        "        else:\n",
        "            emissions = base_emissions * (0.90 + np.random.random() * 0.20)  # 15% variation\n",
        "\n",
        "        loc[\"carbon_emissions\"] = emissions\n",
        "\n",
        "    return locations\n",
        "\n",
        "# water-use efficiency scores\n",
        "def generate_water_efficiency(locations):\n",
        "    # based on climate factors like temperature, humidity, and technology potential\n",
        "\n",
        "    for loc in locations:\n",
        "        lat, lng = loc[\"lat\"], loc[\"lng\"]\n",
        "\n",
        "        # it seems that higher latitudes and elevations typically have better efficiency due to cooler climate, so i just came up with this\n",
        "        base_efficiency = 3.0 + (lat - AZ_MIN_LAT) / (AZ_MAX_LAT - AZ_MIN_LAT) * 2.0\n",
        "\n",
        "        # hot desert areas (e.g., phoenix, yuma) will have poor efficiency\n",
        "        if ((33.0 <= lat <= 34.0) and (-112.5 <= lng <= -111.5)) or (lng < -113.5 and lat < 33.0):\n",
        "            efficiency = 1.5 + np.random.random() * 1.0  # 1.5-2.5 (poor)\n",
        "\n",
        "        #\\higher elevation areas ( e.g., flagstaff, high country) - good efficiency\n",
        "        elif ((35.0 <= lat <= 36.0) and (-112.5 <= lng <= -111.0)):\n",
        "            efficiency = 4.0 + np.random.random() * 1.0  # 4.0-5.0 (excellent)\n",
        "\n",
        "        # mountain transition zones will have moderate to good efficiency\n",
        "        elif ((34.0 <= lat <= 35.0) and (-112.5 <= lng <= -111.0)):\n",
        "            efficiency = 3.0 + np.random.random() * 1.5  # 3.0-4.5 (good)\n",
        "\n",
        "        else:\n",
        "            efficiency = base_efficiency + (np.random.random() - 0.5) * 1.0\n",
        "        efficiency = max(1, min(5, efficiency))\n",
        "        loc[\"water_efficiency\"] = efficiency\n",
        "\n",
        "    return locations\n",
        "\n",
        "# distance function to calculate distances between locations (in km)\n",
        "# lowkey just took this from my old UROP code, idrk if its correct lol\n",
        "def calc_distance(lat1, lon1, lat2, lon2):\n",
        "    R = 6371  # Earth radius in kilometers\n",
        "\n",
        "    # Convert latitude and longitude from degrees to radians\n",
        "    lat1_rad = np.radians(lat1)\n",
        "    lon1_rad = np.radians(lon1)\n",
        "    lat2_rad = np.radians(lat2)\n",
        "    lon2_rad = np.radians(lon2)\n",
        "\n",
        "    # Difference in coordinates\n",
        "    dlat = lat2_rad - lat1_rad\n",
        "    dlon = lon2_rad - lon1_rad\n",
        "\n",
        "    a = np.sin(dlat/2)**2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(dlon/2)**2\n",
        "    c = 2 * np.arcsin(np.sqrt(a))\n",
        "    distance = R * c\n",
        "\n",
        "    return distance\n",
        "\n",
        "# REPLACEMENT - RICHARD, taken from here: https://gis.stackexchange.com/questions/425452/calculate-distance-between-two-lat-lon-alt-points-in-python\n",
        "# from pyproj import Geod\n",
        "# g = Geod(ellps=\"WGS84\")\n",
        "# def calc_distance_alt(lat1, lon1, lat2, lon2):\n",
        "#   _, _, distance = g.inv(lon1, lat1, lon2, lat2)\n",
        "#   return distance\n",
        "\n",
        "# check if a lcation is within arizona's boundaries\n",
        "# this is simplified, w/ real implementation i think we should use a proper shape file\n",
        "# no problem! I should be able to do that in a standard manner, with geopandas. Example: https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoSeries.contains.html#geopandas.GeoSeries.contains - RICHARD\n",
        "def is_in_arizona(lat, lng):\n",
        "  # basically i made it a rectangle\n",
        "    return (AZ_MIN_LAT <= lat <= AZ_MAX_LAT) and (AZ_MIN_LNG <= lng <= AZ_MAX_LNG)\n",
        "\n",
        "# optimization function\n",
        "def optimize_data_center_locations(baseline_centers, potential_locations, min_distance=10):\n",
        "    print(f\"Starting optimization with {len(baseline_centers)} data centers and {len(potential_locations)} potential locations\")\n",
        "    np.random.seed(42)\n",
        "\n",
        "    locations = generate_water_stress(potential_locations)\n",
        "    locations = generate_electricity_prices(locations)\n",
        "    locations = generate_carbon_emissions(locations)\n",
        "    locations = generate_water_efficiency(locations)\n",
        "\n",
        "    location_ids = [loc[\"id\"] for loc in locations]\n",
        "    water_stress = {loc[\"id\"]: loc[\"water_stress\"] for loc in locations}\n",
        "    electricity_price = {loc[\"id\"]: loc[\"electricity_price\"] for loc in locations}\n",
        "    carbon_emissions = {loc[\"id\"]: loc[\"carbon_emissions\"] for loc in locations}\n",
        "    water_efficiency = {loc[\"id\"]: loc[\"water_efficiency\"] for loc in locations}\n",
        "\n",
        "    # coords for distance calculations\n",
        "    location_coords = {loc[\"id\"]: (loc[\"lat\"], loc[\"lng\"]) for loc in locations}\n",
        "\n",
        "    # normalization values for the obj function\n",
        "    max_water_stress = max(water_stress.values())\n",
        "    max_electricity_price = max(electricity_price.values())\n",
        "    max_carbon_emissions = max(carbon_emissions.values())\n",
        "    min_water_efficiency = min(water_efficiency.values())\n",
        "    max_water_efficiency = max(water_efficiency.values())\n",
        "\n",
        "    # objective weights, which can be adjusted based on priorities (kind of chose randomly, so if you want to update at any point, feel free :) )\n",
        "    # sounds great! - RICHARD\n",
        "    # my initial reaction is to set water efficiency weight to zero lol.  but i definitely have some biases/leanings, so we can definitely discuss this. - RICHARD\n",
        "    # another interesting question, kind of taking from my UROP last year, is: at what threshold of objective weights, e.g. on water, do we need before it becomes - RICHARD\n",
        "    # unreasonable to place data centers in hot, desert/dry environments? - RICHARD\n",
        "    # I suppose we can try a few different weightings. (water stress, elec, carbon, water efficiency) = (1, 0, 0, 0), (0, 1, 0, 0), (0, 0, 1, 0), (0, 0, 0, 1), (0.35, 0.25, 0.25, 0.15)\n",
        "    weights = {\n",
        "        \"water_stress\": 0.35,\n",
        "        \"electricity_price\": 0.25,\n",
        "        \"carbon_emissions\": 0.25,\n",
        "        \"water_efficiency\": 0.15\n",
        "    }\n",
        "\n",
        "    model = gp.Model(\"DataCenterOptimization\")\n",
        "\n",
        "    # decision variables: x[d,l] = 1 if data center d is placed at location l\n",
        "    x = {}\n",
        "    for d in range(len(baseline_centers)):\n",
        "        for l in location_ids:\n",
        "            x[d, l] = model.addVar(vtype=GRB.BINARY, name=f\"x_{d}_{l}\")\n",
        "\n",
        "    # minimize weighted combination of metrics\n",
        "    obj = gp.LinExpr()\n",
        "\n",
        "    for d in range(len(baseline_centers)):\n",
        "        for l in location_ids:\n",
        "            # note: for water efficiency, higher is better, so we invert it\n",
        "            # out of curiosity, why not 1 - water_efficiency[l]/max_water_efficiency? But works either way! - RICHARD\n",
        "            normalized_water_efficiency = 1 - (water_efficiency[l] - min_water_efficiency) / (max_water_efficiency - min_water_efficiency)\n",
        "\n",
        "            norm_water_stress = water_stress[l] / max_water_stress\n",
        "            norm_electricity = electricity_price[l] / max_electricity_price\n",
        "            norm_emissions = carbon_emissions[l] / max_carbon_emissions\n",
        "\n",
        "\n",
        "            # I believe that relocating a data center costs around $120,000: https://www.google.com/url?q=https://apposite-tech.com/best-practices-data-center-relocation/&sa=D&source=docs&ust=1744170960046669&usg=AOvVaw1nspqunGp5e_Gn6C7xgrJB. - RICHARD\n",
        "            # Perhaps we could also induce a cost for relocating a data center. So you are more reluctant to actually move a data center unless absolutely necessary. - RICHARD\n",
        "\n",
        "            weighted_sum = (\n",
        "                weights[\"water_stress\"] * norm_water_stress +\n",
        "                weights[\"electricity_price\"] * norm_electricity +\n",
        "                weights[\"carbon_emissions\"] * norm_emissions +\n",
        "                weights[\"water_efficiency\"] * normalized_water_efficiency\n",
        "            )\n",
        "\n",
        "            obj += x[d, l] * weighted_sum\n",
        "\n",
        "    model.setObjective(obj, GRB.MINIMIZE)\n",
        "\n",
        "    # each data center must be placed at exactly one location\n",
        "    for d in range(len(baseline_centers)):\n",
        "        model.addConstr(gp.quicksum(x[d, l] for l in location_ids) == 1, f\"one_loc_per_dc_{d}\")\n",
        "\n",
        "    #each location can have at most one data center\n",
        "    for l in location_ids:\n",
        "        model.addConstr(gp.quicksum(x[d, l] for d in range(len(baseline_centers))) <= 1, f\"one_dc_per_loc_{l}\")\n",
        "\n",
        "    # idk if we need this, but its basically setting a minimum distance between data centers since i dont want the model spitting them out on top of eachy other\n",
        "    # Ooo great point. I feel like this gets at our conversation about why you would ever consider clustering data centers. - RICHARD\n",
        "    # However, I wonder if the water scarcity aspect will naturally cause the model to not cram all the data centers together, if they\n",
        "    # start to pile on too much burden on the local water system. - RICHARD\n",
        "    # Anyhow, I believe the fact that you set the locations in a grid pattern at least gives some minimum spacing. We can keep talking\n",
        "    # about this more if needed! - RICHARD\n",
        "    if min_distance > 0:\n",
        "        location_distances = {}\n",
        "        for l1 in location_ids:\n",
        "            for l2 in location_ids:\n",
        "                if l1 < l2:\n",
        "                    lat1, lng1 = location_coords[l1]\n",
        "                    lat2, lng2 = location_coords[l2]\n",
        "                    dist = calc_distance(lat1, lng1, lat2, lng2)\n",
        "                    location_distances[(l1, l2)] = dist\n",
        "                    location_distances[(l2, l1)] = dist\n",
        "\n",
        "        # so basically, for locations that are too close in lat/lon, prevent placing data centers at both\n",
        "        # I wonder if the below step is contributing to the computational bottleneck. But we don't have to worry about it if it runs\n",
        "        # well on your computer locally :) - RICHARD\n",
        "        for (l1, l2), dist in location_distances.items():\n",
        "            if dist < min_distance:\n",
        "                for d1 in range(len(baseline_centers)):\n",
        "                    for d2 in range(d1 + 1, len(baseline_centers)):\n",
        "                        model.addConstr(x[d1, l1] + x[d2, l2] <= 1, f\"min_dist_{d1}_{l1}_{d2}_{l2}\")\n",
        "\n",
        "    model.optimize()\n",
        "\n",
        "    if model.status == GRB.OPTIMAL:\n",
        "        print(f\"Optimal solution found w/ objective value: {model.objVal}\")\n",
        "\n",
        "        # extract the solution\n",
        "        solution = []\n",
        "        for d in range(len(baseline_centers)):\n",
        "            dc = baseline_centers[d]\n",
        "            for l in location_ids:\n",
        "                if x[d, l].x > 0.5:\n",
        "                    loc_info = next(loc for loc in locations if loc[\"id\"] == l)\n",
        "                    solution.append({\n",
        "                        \"data_center_id\": d,\n",
        "                        \"original_city\": dc[\"city\"],\n",
        "                        \"original_lat\": dc[\"lat\"],\n",
        "                        \"original_lng\": dc[\"lng\"],\n",
        "                        \"new_lat\": loc_info[\"lat\"],\n",
        "                        \"new_lng\": loc_info[\"lng\"],\n",
        "                        \"water_stress\": loc_info[\"water_stress\"],\n",
        "                        \"electricity_price\": loc_info[\"electricity_price\"],\n",
        "                        \"carbon_emissions\": loc_info[\"carbon_emissions\"],\n",
        "                        \"water_efficiency\": loc_info[\"water_efficiency\"],\n",
        "                        \"distance\": calc_distance(\n",
        "                            dc[\"lat\"], dc[\"lng\"],\n",
        "                            loc_info[\"lat\"], loc_info[\"lng\"]\n",
        "                        )\n",
        "                        # feel free to adjujst this list, i was just making sure things seemed okay\n",
        "                    })\n",
        "                    break\n",
        "\n",
        "\n",
        "        # LEFT OFF HERE - RICHARD\n",
        "\n",
        "        baseline_metrics = []\n",
        "        for dc in baseline_centers:\n",
        "            min_dist = float('inf')\n",
        "            closest_loc = None\n",
        "\n",
        "            for loc in locations:\n",
        "                dist = calc_distance(dc[\"lat\"], dc[\"lng\"], loc[\"lat\"], loc[\"lng\"])\n",
        "                if dist < min_dist:\n",
        "                    min_dist = dist\n",
        "                    closest_loc = loc\n",
        "\n",
        "            baseline_metrics.append({\n",
        "                \"city\": dc[\"city\"],\n",
        "                \"lat\": dc[\"lat\"],\n",
        "                \"lng\": dc[\"lng\"],\n",
        "                \"water_stress\": closest_loc[\"water_stress\"],\n",
        "                \"electricity_price\": closest_loc[\"electricity_price\"],\n",
        "                \"carbon_emissions\": closest_loc[\"carbon_emissions\"],\n",
        "                \"water_efficiency\": closest_loc[\"water_efficiency\"]\n",
        "            })\n",
        "\n",
        "        # just to see the average metrics\n",
        "        baseline_avg = {\n",
        "            \"water_stress\": sum(b[\"water_stress\"] for b in baseline_metrics) / len(baseline_metrics),\n",
        "            \"electricity_price\": sum(b[\"electricity_price\"] for b in baseline_metrics) / len(baseline_metrics),\n",
        "            \"carbon_emissions\": sum(b[\"carbon_emissions\"] for b in baseline_metrics) / len(baseline_metrics),\n",
        "            \"water_efficiency\": sum(b[\"water_efficiency\"] for b in baseline_metrics) / len(baseline_metrics)\n",
        "        }\n",
        "\n",
        "        optimized_avg = {\n",
        "            \"water_stress\": sum(s[\"water_stress\"] for s in solution) / len(solution),\n",
        "            \"electricity_price\": sum(s[\"electricity_price\"] for s in solution) / len(solution),\n",
        "            \"carbon_emissions\": sum(s[\"carbon_emissions\"] for s in solution) / len(solution),\n",
        "            \"water_efficiency\": sum(s[\"water_efficiency\"] for s in solution) / len(solution),\n",
        "            \"avg_distance\": sum(s[\"distance\"] for s in solution) / len(solution)\n",
        "        }\n",
        "\n",
        "        # here are the metrics compared to the original ben chmark\n",
        "        print(\"\\nMetrics Comparison:\")\n",
        "        print(f\"Water Stress: {baseline_avg['water_stress']:.2f}  {optimized_avg['water_stress']:.2f} \" +\n",
        "              f\"({((baseline_avg['water_stress'] - optimized_avg['water_stress']) / baseline_avg['water_stress'] * 100):.2f}% improvement)\")\n",
        "\n",
        "        print(f\"Electricity Price: ${baseline_avg['electricity_price']:.4f}/kWh  ${optimized_avg['electricity_price']:.4f}/kWh \" +\n",
        "              f\"({((baseline_avg['electricity_price'] - optimized_avg['electricity_price']) / baseline_avg['electricity_price'] * 100):.2f}% improvement)\")\n",
        "\n",
        "        print(f\"Carbon Emissions: {baseline_avg['carbon_emissions']:.4f} tons CO2/MWh  {optimized_avg['carbon_emissions']:.4f} tons CO2/MWh \" +\n",
        "              f\"({((baseline_avg['carbon_emissions'] - optimized_avg['carbon_emissions']) / baseline_avg['carbon_emissions'] * 100):.2f}% improvement)\")\n",
        "\n",
        "        print(f\"Water Efficiency: {baseline_avg['water_efficiency']:.2f}  {optimized_avg['water_efficiency']:.2f} \" +\n",
        "              f\"({((optimized_avg['water_efficiency'] - baseline_avg['water_efficiency']) / baseline_avg['water_efficiency'] * 100):.2f}% improvement)\")\n",
        "\n",
        "        print(f\"Average Relocation Distance: {optimized_avg['avg_distance']:.2f} km\")\n",
        "\n",
        "        return {\n",
        "            \"objective_value\": model.objVal,\n",
        "            \"solution\": solution,\n",
        "            \"baseline\": baseline_metrics,\n",
        "            \"metrics\": {\n",
        "                \"baseline\": baseline_avg,\n",
        "                \"optimized\": optimized_avg\n",
        "            }\n",
        "        }\n",
        "    else:\n",
        "        print(f\"No optimal solution found. Status: {model.status}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "# \\main execution\n",
        "if __name__ == \"__main__\":\n",
        "  #grid resoljution\n",
        "    resolution = 0.25  # 0.25 degrees = ~28 km\n",
        "\n",
        "    # adjust the spacing based on longitude (since longitude degrees are smaller at higher latitudes)\n",
        "    # again, this is from my old UROP, so could be slightly off\n",
        "    avg_lat = (AZ_MIN_LAT + AZ_MAX_LAT) / 2\n",
        "    lng_spacing = resolution / np.cos(np.radians(avg_lat))\n",
        "\n",
        "    # create baseline data centers (129 total for az)\n",
        "    baseline_centers = create_baseline_centers()\n",
        "    print(f\"Created {len(baseline_centers)} baseline data centers\")\n",
        "\n",
        "    # make a grid of potential locations\n",
        "    potential_locations = create_location_grid(resolution)\n",
        "    print(f\"Created {len(potential_locations)} potential locations\")\n",
        "\n",
        "    # minimum distance between data centers (in km)\n",
        "    # just set it to 0 to disable this constraint\n",
        "    min_distance = 20  # km\n",
        "\n",
        "    results = optimize_data_center_locations(baseline_centers, potential_locations, min_distance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HxFfgSQHAYo",
        "outputId": "b2d76246-a160-4b31-8c6b-88cdf33ef4ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gurobipy\n",
            "  Downloading gurobipy-12.0.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (16 kB)\n",
            "Downloading gurobipy-12.0.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (14.4 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m14.4/14.4 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gurobipy\n",
            "Successfully installed gurobipy-12.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install gurobipy"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
